<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Using the AI Model for Batch Summarization :: vLLM Optimizing and Serving Models on OpenShift AI</title>
    <link rel="prev" href="rhoai_query.html">
    <link rel="next" href="../appendix/appendix.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="genai-vllm" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../vllm/index.html">vLLM, What is it?</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_intro.html">vLLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/rh_ai.html">Red Hat AI Platforms</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_rhoai.html">Integrating vLLM with OpenShift AI: The Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_deploy.html">vLLM on Red Hat OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_concl.html">Summary: Key Takeaways and Next Steps</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../model_sizing/index.html">GPU Architecture and Model Sizing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_arch.html">NVIDIA GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_cost.html">Estimating GPU VRAM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/vram_calc.html">Cost-Effective Model Selection</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rh_hg_ai/index.html">Red Hat AI Model Repository</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/model_types.html">Generative AI Model Variations in Model Naming</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/val_models.html">Validated Models and Quantization Strategies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/lab_models.html">Pre-Selected Course Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/summary.html">From Curation to Confident Deployment</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_self.html">Optional - RHOAI Self-Managed</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_221.html">Lab Environment Customization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_config.html">Project and Data Connection Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_bench.html">Creating the AI Workbench and Preparing Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="add_runtime.html">vLLM Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_model.html">Deploy Granite LLM on RHOAI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_query.html">Querying the Deployed Model in a Jupyter Notebook</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="batch_summ.html">Using the AI Model for Batch Summarization</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/further_study.html">Hands on Exploration and Further Study</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Hub: Lab Environment Selection</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/developer_sandbox.html">Red Hat Developer Platform</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM Optimizing and Serving Models on OpenShift AI</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></li>
    <li><a href="index.html">OpenShift AI Configuration</a></li>
    <li><a href="batch_summ.html">Using the AI Model for Batch Summarization</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Using the AI Model for Batch Summarization</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>In this hands-on lab, you will use the OpenShift AI workbench and a Jupyter environment to perform a practical, real-world task: summarizing support tickets. This demonstrates how a Large Language Model (LLM) can be used in a batch-processing workflow to increase efficiency and speed up analysis.</p>
</div>
<div class="paragraph">
<p>Within the Jupyter environment, you should have already cloned the <code>genai-apps</code> git repository. For this lab, you&#8217;ll navigate to the <code>genai-vllm</code> directory and open the <code>batch_summarize_query.ipynb</code> notebook.</p>
</div>
<div class="paragraph">
<p>This notebook simulates a scenario where you have a folder of support tickets in JSON format. You&#8217;ll use your deployed model to automatically:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Read each ticket.</p>
</li>
<li>
<p>Generate a concise, one-sentence summary of the issue.</p>
</li>
<li>
<p>Suggest potential troubleshooting steps.</p>
</li>
<li>
<p>Save this analysis to a new summary file.</p>
</li>
</ol>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_step_1_install_required_libraries"><a class="anchor" href="#_step_1_install_required_libraries"></a>Step 1: Install Required Libraries</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The first code cell ensures that the necessary Python packages are installed in your workbench environment. It uses the <code>%pip</code> command to install <strong>langchain-openai</strong>, which helps in interacting with the model, and <strong>httpx</strong>, which handles the underlying API requests.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_step_2_imports_and_configuration"><a class="anchor" href="#_step_2_imports_and_configuration"></a>Step 2: Imports and Configuration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The next cell imports the required libraries and, most importantly, configures the connection to your deployed model. <strong>This is the primary section you will need to edit.</strong></p>
</div>
<div class="sect2">
<h3 id="_action_required_configure_connection_variables"><a class="anchor" href="#_action_required_configure_connection_variables"></a>Action Required: Configure Connection Variables</h3>
<div class="paragraph">
<p>To connect to your model, you must provide three key pieces of information. This design allows you to easily reuse the notebook to test and compare the summarization capabilities of different models using the same set of sample tickets.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>BASE_URL</code>: Set this to the <strong>Inference endpoint</strong> URL from your model&#8217;s deployment page.</p>
</li>
<li>
<p><code>API_KEY</code>: Set this to the <strong>Authentication Token</strong> for your deployed model.</p>
</li>
<li>
<p><code>MODEL_NAME</code>: Set this to the name you gave your deployment in OpenShift AI (e.g., "granite-model").</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># --- ❗ACTION REQUIRED: REPLACE VALUES BELOW ❗---

# Model and Connection Details
MODEL_NAME = "granite" # The name of your model deployment
BASE_URL = "https://your-model-inference-url.apps.cluster.com/v1" # Replace with your Inference Endpoint
API_KEY = "sha256~your-long-authentication-token" # Replace with your Authentication Token

# -----------------------------------------------------

# Directory and File Handling Configuration
INPUT_FOLDER = "support_tickets"
# This is the key in the JSON file that contains the main ticket text.
JSON_TICKET_KEY = "issue_description"</code></pre>
</div>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_step_3_prepare_sample_data"><a class="anchor" href="#_step_3_prepare_sample_data"></a>Step 3: Prepare Sample Data</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This cell makes the lab self-contained by programmatically creating a <code>support_tickets</code> directory and populating it with two sample tickets in <code>.json</code> format. While the provided git repository contains 15 tickets, this cell overwrites the first two as a demonstration.</p>
</div>
<div class="paragraph">
<p>This serves as a useful example of how data can be generated or prepared directly within a notebook for testing purposes.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_step_4_initialize_the_llm_client"><a class="anchor" href="#_step_4_initialize_the_llm_client"></a>Step 4: Initialize the LLM Client</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This cell takes the configuration variables you set in Step 2 and creates the <code>ChatOpenAI</code> client. Note the following parameters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong><code>temperature=0.1</code></strong>: A low temperature encourages the model to provide more factual and deterministic responses, which is ideal for a support context.</p>
</li>
<li>
<p><strong><code>http_client=httpx.Client(verify=False)</code></strong>: This setting disables SSL verification and is often necessary for lab environments that use self-signed certificates.</p>
</li>
</ul>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_step_5_define_the_core_processing_function"><a class="anchor" href="#_step_5_define_the_core_processing_function"></a>Step 5: Define the Core Processing Function</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This cell contains the <code>analyze_and_summarize_ticket</code> function, which is the "brains" of the operation. This is where the <strong>prompt engineering</strong> happens.</p>
</div>
<div class="paragraph">
<p>The prompt is a multi-line string that gives the LLM its persona ("You are a senior support engineer") and a clear, structured set of tasks:
1. Provide a one-sentence summary.
2. List potential troubleshooting steps.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_step_6_run_the_batch_process"><a class="anchor" href="#_step_6_run_the_batch_process"></a>Step 6: Run the Batch Process</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This cell executes the main processing loop. When run, the code will:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Find all <code>.json</code> files in the <code>support_tickets</code> directory.</p>
</li>
<li>
<p>Loop through each file, printing its name as it processes.</p>
</li>
<li>
<p>Call the analysis function from Step 5 for each ticket.</p>
</li>
<li>
<p>Save the model&#8217;s response to a new <code>_summary.txt</code> file in the same directory.</p>
</li>
</ol>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_step_7_verify_the_output"><a class="anchor" href="#_step_7_verify_the_output"></a>Step 7: Verify the Output</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The final cell is for verification. It lists the contents of the <code>support_tickets</code> directory so you can see the newly created summary files. It then prints the content of the first summary file (<code>ticket_001_summary.txt</code>) to confirm that the entire workflow was successful.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_interactive_demo_query_a_machine_learning_model_from_a_jupyter_notebook"><a class="anchor" href="#_interactive_demo_query_a_machine_learning_model_from_a_jupyter_notebook"></a>Interactive Demo: Query a Machine Learning Model from a Jupyter Notebook</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The following interactive demonstration will walk you through the process of:
1.  Simulating summarization of support tickets use case
3.  Replace URL ENDPOINT, MODEL_NAME, and API TOKEN in the example notebook.
4.  Experimentation with various prompts to see how the model responds.</p>
</div>
<div class="paragraph">
<p>Follow the on-screen prompts in the demo to complete the model deployment.</p>
</div>
<iframe
  src="https://demo.arcade.software/kfx35IMXnxrklUUmNwlT?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%"
  height="600px"
  frameborder="0"
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="rhoai_query.html">Querying the Deployed Model in a Jupyter Notebook</a></span>
  <span class="next"><a href="../appendix/appendix.html">Appendix</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
