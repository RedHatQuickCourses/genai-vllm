<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Model Selection: Why We Chose Granite :: vLLM Optimizing and Serving Models on OpenShift AI</title>
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="genai-vllm" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Hub: Lab Environment Selection</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/developer_sandbox.html">Red Hat Developer Platform</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../vllm/index.html">vLLM Overview</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_intro.html">vLLM and Red Hat AI Platforms</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_rhoai.html">Integrating vLLM with OpenShift AI: The Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_deploy.html">Deploying and Interacting with Models on OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_concl.html">vLLM Technical Deep Dive and Advanced Capabilities</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../model_sizing/index.html">GPU Architecture and Model Sizing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_cost.html">Estimating GPU VRAM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_arch.html">Optimizing with NVIDIA GPU Architecture</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rh_hg_ai/index.html">Red Hat AI Model Repository</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/model_types.html">The Red Hat AI Validated Model Repository</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/val_models.html">Intro Quantization Strategies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/lab_models.html">Granite Models</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rhoai_deploy/index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_self.html">Optional - RHOAI Self-Managed</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_221.html">Lab Environment Customization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_config.html">Project and Data Connection Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_bench.html">Creating the AI Workbench and Preparing Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/add_runtime.html">vLLM Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_model.html">Deploy Granite LLM on RHOAI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_query.html">Querying the Deployed Model in a Jupyter Notebook</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/batch_summ.html">Using the AI Model for Batch Summarization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/guide_llm.html">Performance Benchmarking with GuideLLM</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM Optimizing and Serving Models on OpenShift AI</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></li>
    <li><a href="vllm_intro.html">Model Selection: Why We Chose Granite</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Model Selection: Why We Chose Granite</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Welcome to the Granite family of models. This page explains what Granite models are, why the <code>Granite-3.3-2B-instruct</code> model was selected for this course, and how it fits into the broader ecosystem of enterprise-ready AI.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_are_granite_models"><a class="anchor" href="#_what_are_granite_models"></a>What are Granite Models?</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Granite</strong> is a series of large language models (LLMs) created by IBM specifically for enterprise applications. Unlike some other models, the Granite family is built with the needs of businesses at the forefront, emphasizing trust, transparency, and practical application.</p>
</div>
<div class="paragraph">
<p>What truly sets Granite models apart for enterprise use are two key factors:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Open and Assured</strong>: The models are open-sourced under the <strong>Apache 2.0 license</strong>. This allows developers to freely experiment, modify, and deploy the models in their own environmentsâ€”a critical feature for organizations handling sensitive data that cannot rely on external services.</p>
</li>
<li>
<p><strong>Transparent Training Data</strong>: IBM discloses the data used to train the models, building a foundation of trust and making them more suitable and auditable for enterprise environments.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_granite_family_a_model_for_every_need"><a class="anchor" href="#_the_granite_family_a_model_for_every_need"></a>The Granite Family: A Model for Every Need</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Granite is not a single model but a diverse suite designed for various enterprise tasks. This ecosystem approach means you can select the right tool for the job.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Granite Language Models</strong></dt>
<dd>
<p>Base and instruction-tuned models with strong reasoning capabilities, ideal for agentic workflows, Retrieval-Augmented Generation (RAG), summarization, and content generation.</p>
</dd>
<dt class="hdlist1"><strong>Granite Vision Models</strong></dt>
<dd>
<p>Specialized models for document and image understanding across a range of file types and resolutions.</p>
</dd>
<dt class="hdlist1"><strong>Granite Speech Models</strong></dt>
<dd>
<p>Compact and efficient models for high-performance transcription and translation tasks.</p>
</dd>
<dt class="hdlist1"><strong>Granite for Time Series</strong></dt>
<dd>
<p>Lightweight, pre-trained models for time-series forecasting, optimized to run efficiently on various hardware.</p>
</dd>
<dt class="hdlist1"><strong>Granite Guardian</strong></dt>
<dd>
<p>A safety-focused model designed to mitigate risks and safeguard AI applications by screening for harmful content in both user prompts and LLM responses.</p>
</dd>
<dt class="hdlist1"><strong>Granite for Geospatial Data</strong></dt>
<dd>
<p>A foundational model created in partnership with NASA, built on large-scale satellite and remote sensing data.</p>
</dd>
<dt class="hdlist1"><strong>Granite Embedding Models</strong></dt>
<dd>
<p>Models designed to enhance the understanding of user intent, crucial for improving the relevance of information in search and RAG applications.</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_our_course_model_a_deep_dive_into_granite_3_3_2b_instruct"><a class="anchor" href="#_our_course_model_a_deep_dive_into_granite_3_3_2b_instruct"></a>Our Course Model: A Deep Dive into Granite-3.3-2B-Instruct</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The primary model used throughout this course is <code>ibm-granite/granite-3.3-2b-instruct</code>. It represents a perfect balance of modern features, manageable size, and robust performance for our learning objectives.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Model Snapshot</div>
<div class="ulist">
<ul>
<li>
<p><strong>Developers</strong>: Granite Team, IBM</p>
</li>
<li>
<p><strong>Release Date</strong>: April 16th, 2025</p>
</li>
<li>
<p><strong>License</strong>: Apache 2.0</p>
</li>
<li>
<p><strong>GitHub</strong>: <a href="https://github.com/ibm-granite/granite-3.3-language-models">ibm-granite/granite-3.3-language-models</a></p>
</li>
<li>
<p><strong>Context Length</strong>: 128,000 tokens</p>
</li>
<li>
<p><strong>Supported Languages</strong>: Excellent in English, with support for German, Spanish, French, Japanese, and more.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>This is a <strong>2-billion parameter</strong> instruction-following model fine-tuned for enhanced reasoning. It supports structured outputs using <code>&lt;think&gt;</code> and <code>&lt;response&gt;</code> tags, which provides a clear separation between the model&#8217;s internal "thought process" and the final answer, a valuable feature for debugging and creating reliable AI agents.</p>
</div>
<div class="sect2">
<h3 id="_key_capabilities"><a class="anchor" href="#_key_capabilities"></a>Key Capabilities</h3>
<div class="paragraph">
<p>The model is designed for a wide range of enterprise tasks, including:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Retrieval Augmented Generation (RAG)</p>
</li>
<li>
<p>Question-Answering and Summarization</p>
</li>
<li>
<p>Text classification and extraction</p>
</li>
<li>
<p>Code generation and function-calling</p>
</li>
<li>
<p>Long-context tasks (e.g., summarizing long documents or meetings)</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_selection_story_a_practical_choice_for_this_course"><a class="anchor" href="#_the_selection_story_a_practical_choice_for_this_course"></a>The Selection Story: A Practical Choice for This Course</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Choosing the right model for a course involves balancing performance, accessibility, and relevance to real-world engineering challenges. Hereâ€™s why <code>Granite-3.3-2B-instruct</code> was the ideal choice:</p>
</div>
<div class="paragraph">
<div class="title">A Forward-Looking Foundation</div>
<p>The selection process began with a key technical goal in mind: <strong>quantization</strong>. We needed a full-sized base model that was powerful enough to be useful but small enough to be a practical candidate for a future lab on model optimization. At 2 billion parameters, it hits this sweet spot perfectly.</p>
</div>
<div class="paragraph">
<div class="title">The Sweet Spot of Performance and Resources</div>
<p>For AI platform engineers, resource management is critical. A major advantage of this model is its ability to deliver exceptional performance within a manageable resource footprint. Paired with its huge <strong>128K context window</strong>, it allows for sophisticated, long-document analysis while fitting comfortably on a standard <strong>24GB GPU</strong>, a common hardware profile in enterprise labs.</p>
</div>
<div class="paragraph">
<div class="title">Exceeding Expectations</div>
<p>Throughout the development of this course, the model consistently provided accurate answers and demonstrated impressive capabilities. While extensive benchmarks against every available model weren&#8217;t performed, its performance for a model of its size far exceeded all initial expectations.</p>
</div>
<div class="sect2">
<h3 id="_looking_ahead_the_evolution_of_granite"><a class="anchor" href="#_looking_ahead_the_evolution_of_granite"></a>Looking Ahead: The Evolution of Granite</h3>
<div class="paragraph">
<p>The world of AI moves fast, and the Granite 4 models are now available. Future iterations of this course may incorporate these newer models. This presents an exciting opportunity to create a lab focused on <strong>comparing generational improvements</strong>, allowing students to benchmark the gains in performance, efficiency, and capability from one model generation to the nextâ€”a common and valuable task in enterprise AI.</p>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
