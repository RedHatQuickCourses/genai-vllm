= vLLM: From Model to Deployment
:navtitle: Home

== Introduction

Course Title: vLLM: From Model to Deployment

Description:

Deploying large language models (LLMs) in a real-world enterprise environment comes with its unique set of challengesâ€”from selecting the right model within budget constraints to ensuring seamless integration and robust performance. 

This course, vLLM: From Model to Deployment, is designed to cut through that complexity, providing you with the practical skills and knowledge to confidently bring your AI initiatives to life.

Our mission is straightforward: to guide you through the complete lifecycle of deploying a vLLM instance, empowering you to demonstrate the tangible delivery of a functional AI engine.

Duration: 1-2 hours

== Objectives

On completing this course, you should be able to:

* Select a model from the Red Hat AI Model Repository.
* Deploy selected optimized model using OpenShift AI.
* Query that model using RHOAI Workbench + Notebook.

== Prerequisites

This course assumes that you have the following prior experience:

* Understanding of LLM compression techniques such as quantization and sparzation.
* Knowledge of OpenShift AI Dashboard Menus and Tabs.
* Knowledge of Jupyter notebooks and Python.
* vLLM Inference server (runtime) and vLLM Compressor.

[NOTE]
====
.Quick interactive introduction to using and customizing your Workbench (recommended)

(This Interactive demo.)
++++
<iframe 
  src="https://demo.arcade.software/0ttb9MxpcNxWhaF1e49W?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%" 
  height="600px" 
  frameborder="0" 
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
++++
====


++++
<iframe 
  src="https://demo.arcade.software/0ttb9MxpcNxWhaF1e49W?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%" 
  height="600px" 
  frameborder="0" 
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
++++

