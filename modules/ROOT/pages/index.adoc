= vLLM: Optimizing and Serving Models on OpenShift AI
:navtitle: Home

== Introduction

Deploying large language models in an enterprise environment is a high-stakes game. While the promise of AI is massive, the reality is often plagued by slow inference speeds, high resource consumption, and budget overruns. How do you deliver a solution that is not only powerful but also practical and performant?

This course provides the answer. We dive deep into solving the critical "last mile" problem of AI delivery: efficient model inference. You will learn to harness the power of vLLM on OpenShift AI, a combination that unlocks significant performance gains and dramatically reduces operational costs.

Our mission is to equip you with the skills to turn AI potential into production reality. We will walk you through a complete, real-world workflow: from selecting the right model in the Red Hat AI catalog to deploying it with vLLM for unparalleled inference speed. By the end of this course, you won't just have a theoretical understanding; you will have the practical ability to build, measure, and deliver a high-performance AI service. This is the key to unlocking successful AI incubators and impressing stakeholders by demonstrating a solution that is not only smart but also economically viable.

==== Duration: 1-2 hours

== Objectives

On completing this course, you should be able to:

* *Select Models Strategically:* Choose a capable model from the Red Hat AI Model Repository based on both performance and budget.
* *Deploy for Performance:* Implement multiple, optimized models on OpenShift AI using the vLLM engine.
* *Query and Test:* Interact with your deployed models using the RHOAI Workbench and Jupyter Notebooks.
* *Evaluate and Prove:* Use a guide LLM to evaluate your model's performance and demonstrate its value.

== Prerequisites

The following courses and labs are recommended before attempting this course:

 * https://training-lms.redhat.com/sso/saml/auth/rhlpint?RelayState=deeplinklp%3D78588241[Practical Approach to RHOAI Series.,window=blank]
 * https://training-lms.redhat.com/sso/saml/auth/rhlpint?RelayState=deeplinkoffering%3D79898868[vLLM - Technical Reference Guide v.101, window=blank]
 * https://training-lms.redhat.com/sso/saml/auth/rhlpint?RelayState=deeplinkoffering%3D81576358[LLM Compressor for vLLM - Technical Reference - v.101, window=blank]   

== Interactive Experiences

This course features a series of interactive experiences designed to provide a hands-on learning environment. These modules simulate real-world lab scenarios, requiring you to click on specific hotspots to advance through the steps. Think of these as guided, self-paced walkthroughs of tasks like configuring OpenShift AI or deploying a model for inference with vLLM. This interactive format is designed to build procedural muscle memory and deepen your understanding of the end-to-end workflow, ensuring you can confidently apply these skills in customer engagements.

[NOTE]
====
.Quick interactive introduction to using and customizing your Workbench (recommended)

(This Interactive demo.)
++++
<iframe 
  src="https://demo.arcade.software/0ttb9MxpcNxWhaF1e49W?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%" 
  height="600px" 
  frameborder="0" 
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
++++
====

////
Preamble: Course Information
[preamble]
Audience:: AI Platform Engineers, ML Engineers, AI Consultants
Level:: Intermediate
Prerequisites:: Foundational knowledge of Large Language Models (LLMs), containerization (Docker), and REST APIs. Familiarity with GPU hardware is beneficial.
Version:: 1.0
////

== Acknowledgements

* Ravi Srinivasan
* Rupali Talwatkar
* Sam Zahran
* Caitlyn Rymarchyk
* The OpenShift AI team
* Samuel Monson - for writing an awesome GuideLLM notebook.
* Karlos Knox