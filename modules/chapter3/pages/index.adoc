= Red Hat AI Model Repository

What is it ?

== Red Hat AI -  Build AI for your world

The Red Hat AI repository on Hugging Face is an open-source initiative backed by deep collaboration between IBM and Red Hat’s research, engineering, and business units. We’re committed to making AI more accessible, efficient, and community-driven from research to production.

We believe the future of AI is open. That’s why we’re sharing our latest models and research on Hugging Face, which are freely available to help researchers, developers, and organizations deploy high-performance AI at scale.

== Red Hat AI validated models
Run inference on any red hat platform. 

To support this, Red Hat AI provides access to a repository of third-party models that are validated to run efficiently across the platform. This set of leading third-party models are run through capacity guidance planning scenarios, so you can make informed decisions about the right combination of model, deployment settings, and hardware accelerator for your domain specific use cases.

Red Hat intends to release a new set of validated models on a monthly basis following the cadence of upstream vLLM releases. Red Hat reserves the right to stop validating models for any reason.


=== Red Hat AI validated models - v1.0 Collection

v1.0 Collection of third-party generative AI models validated by Red Hat AI for use across the Red Hat AI Product Portfolio.

 * Gemma-3 Quantized

 * Whisper Quantized

 * Llama 4 Quantized

 * Qwen3 Quantized

 * Mistral Small-3.1 Instruct Quantized

 * Phi-4 Quantized

 * Llama 3.3 70B Instruct Quantized

 * Qwen 2.5 Quantized

 * Granite Quanztied

There are also models available but have not been validated.  

We select three models based on randomized selection of models that met the requirements.

 * Function on L4 Nvidia video cards (24GB video memory).
 * < 75,000 yearly budget.
 * Improve ticket closure speed by Engineering team members by 25%. 



Key Benefits?

 . Maximize inference efficiency across hardware using production-grade compression and optimization techniques like quantization (FP8, INT8, INT4), structured/unstructured sparsity, distillation, and more, ready for cost-efficient deployments with vLLM.
. Validated models by Red Hat AI offer confidence, predictability, and flexibility when deploying third-party generative AI models across the Red Hat AI platform. Red Hat AI validates models by running a series of capacity planning scenarios with GuideLLM for benchmarking, Language Model Evaluation Harness for accuracy evaluations, and vLLM for inference serving across a wide variety of AI acclerators.

== Pre-Selected models - 

 * Mistral-Small-3.1-24B-Instruct-2503-quantized.w4a16

 * RedHatAI/Qwen2.5-VL-3B-Instruct-quantized.w8a8

 * RedHatAI/gemma-3-4b-it-quantized.w4a16



== Evaluate each one in-depth



== Select a Model to deploy. 


