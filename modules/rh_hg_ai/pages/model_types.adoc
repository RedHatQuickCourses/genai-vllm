= The Red Hat AI Validated Model Repository

The open-source AI landscape, particularly on platforms like Hugging Face, presents a vast and often challenging environment due to the sheer number of available models, making it difficult to discern which are performant, accurate, or truly ready for enterprise use. To address this complexity, the **Red Hat AI Validated Model Repository** emerges as a curated ecosystem designed to streamline model selection and deployment.

== What is the Red Hat AI Validated Model Repository?

It is an open-source initiative stemming from a deep collaboration between IBM and Red Hat. Its primary mission is to **bridge the gap between cutting-edge research and robust production deployments** by offering open, accessible, and community-driven AI solutions. Far from being just a list of models, it functions as a strategic solution to **de-risk AI projects** by providing models that have been pre-vetted for performance, accuracy, and overall enterprise readiness.


== Why Use a Validated Model?

For AI platform delivery engineers, utilizing models from this repository offers significant advantages:

[IMPORTANT]
.Key Benefits of Using a Validated Model
****
* **Reduces Guesswork:** Provides reliable performance expectations and recommended deployment settings, eliminating the need for extensive trial-and-error.
* **Ensures Enterprise Readiness:** Validates that models perform well under load using enterprise-grade tools like vLLM.
* **Optimizes for Cost:** Offers clear guidance on pairing models with the right hardware, maximizing inference efficiency and lowering Total Cost of Ownership (TCO).
* **Provides Flexibility:** Offers a range of popular models in various optimized formats to meet diverse project requirements.
****



== The Rigorous Validation Process

The confidence in Red Hat's validated models stems from a rigorous and transparent validation process that employs industry-standard open-source tooling, ensuring reproducibility of results. The key tools involved are:

 *   **GuideLLM**: A powerful benchmarking tool used for capacity planning. It simulates real-world traffic to assess a model’s throughput, latency, and resource utilization across different hardware configurations.
 *   **Language Model Evaluation Harness (LM Eval Harness)**: This is the industry standard for **accuracy evaluation**. It measures a model’s reasoning and generalization capabilities across a wide range of academic benchmarks.
 *   **vLLM**: This specific inference engine is used during the performance validation itself, ensuring that the benchmarks reflect the performance achievable when deploying with vLLM on OpenShift AI.

This thorough validation process provides the transparent data necessary for making informed decisions and setting realistic expectations for model performance on target hardware.

== v1.0 Collection of Red Hat AI Validated Models

This initial collection features leading third-party generative AI models rigorously validated for efficient use across the Red Hat AI Product Portfolio. Each model listed below has associated configurations for various quantization levels (e.g., `w4a16` for 4-bit weights and 16-bit activations, `w8a8` for 8-bit weights and 8-bit activations, or `FP8-dynamic` for dynamic FP8 quantization).

* Gemma-3 Quantized
* Whisper Quantized (Note: Whisper is typically an ASR model, but its text-generation component is relevant)
* Llama 4 Quantized
* Qwen3 Quantized
* Mistral Small-3.1 Instruct Quantized
* Phi-4 Quantized
* Llama 3.3 70B Instruct Quantized
* Qwen 2.5 Quantized
* Granite Quantized

[NOTE]
The specific quantization scheme (e.g., `w4a16`, `w8a8`, `FP8-dynamic`) for each model is typically indicated in its full name or metadata within the Red Hat AI Hugging Face repository. These notations signify the precision used for weights (w) and activations (a), or the dynamic FP8 method.

==== Availability and Selection Criteria

While Red Hat AI focuses on validated models, other models may also be available in the repository but have not undergone the full validation process. For practical deployment in this course, we will focus on specific pre-selected models from the validated collection.