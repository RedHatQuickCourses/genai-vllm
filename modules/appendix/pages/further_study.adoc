= Hands on Exploration and Further Study

This section provides a curated collection of blogs, interactive experiences, vLLM office hours, and
YouTube videos to deepen your understanding of vLLM, including practical guidance on setup, usage,
optimization, and multimodal inference, along with opportunities for hands-on learning with vLLM and
related tools.

=== Blogs:

 * vLLM: Easy, Fast, and Cheap LLM Serving with Page Attention
 * LLM Compressor is here: Faster inference with vLLM
 * vLLM V1: Accelerating multimodal inference for large language models
 * vLLM V1 User Guide

=== Interactive experiences:

 * Introduction to Red Hat AI Inference Server
 *  Hands on with vLLM
 * LLM Compression and Model Optimization

=== vLLM Office Hours:

 * vLLM Office Hours #22 - Intro