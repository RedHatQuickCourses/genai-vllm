{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ce300",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640de9d",
   "metadata": {},
   "source": [
    "replace the Model name with the name of model deployment on OpenShift AI\n",
    "\n",
    "replace the url with the external inference URL\n",
    "\n",
    "add the API key from the bottom of the model serving page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define the connection parameters for your Granite model\n",
    "MODEL_NAME = \"granite\"  # Or the specific model you intend to use\n",
    "BASE_URL = \"https://granite-innovatech.apps.cluster-g5vp6.g5vp6.sandbox512.opentlc.com/v1\"\n",
    "# If your endpoint requires an API key, set it here. Otherwise, it can be a placeholder.\n",
    "API_KEY = \"EMPTY\" \n",
    "\n",
    "# --- Optional: Advanced Configuration ---\n",
    "# Set a timeout for API requests (in seconds)\n",
    "# timeout = httpx.Timeout(60.0)\n",
    "\n",
    "# If your environment requires it, you can disable SSL certificate verification.\n",
    "# Note: This is not recommended for production environments.\n",
    "# http_client = httpx.Client(verify=False, timeout=timeout)\n",
    "# -----------------------------------------\n",
    "\n",
    "try:\n",
    "    # Initialize the ChatOpenAI client\n",
    "    llm = ChatOpenAI(\n",
    "        model=MODEL_NAME,\n",
    "        api_key=API_KEY,\n",
    "        base_url=BASE_URL,\n",
    "        # Uncomment the line below to use custom httpx client settings\n",
    "        # http_client=http_client,\n",
    "    )\n",
    "\n",
    "    # Prepare the messages for the model\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        HumanMessage(content=\"What is OpenShift?\"),\n",
    "    ]\n",
    "\n",
    "    # Invoke the model and get the response\n",
    "    print(\"Sending request to the Granite model...\")\n",
    "    ai_msg = llm.invoke(messages)\n",
    "\n",
    "    # Print the content of the response\n",
    "    print(\"\\nResponse from Granite Model:\")\n",
    "    print(ai_msg.content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc52851",
   "metadata": {},
   "source": [
    "Next Section - iterated through a series of json files in a folder and queries the model for a summarization of the object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ccf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import httpx\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Model and Connection Details\n",
    "MODEL_NAME = \"granitev2\"\n",
    "BASE_URL = \"https://granitev2-innovatech.apps.cluster-g5vp6.g5vp6.sandbox512.opentlc.com/v1\"\n",
    "API_KEY = \"eyJhbGciOiJSUzI1NiIsImtpZCI6ImFKSE0zZ3pMS3NkdHZZT1FjWmljNTk4SnJFM0FrX3lSajZuS2dSYVVZbG8ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJpbm5vdmF0ZWNoIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6Imtub3gtZ3Jhbml0ZXYyLXNhIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImdyYW5pdGV2Mi1zYSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImE0YWQ4YTQzLWEwYjYtNDQ4MS1iZWViLTMzZGI4MTJhZWQ3OCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDppbm5vdmF0ZWNoOmdyYW5pdGV2Mi1zYSJ9.rVmF7kLG9FpmHzfPm9_9AgbLEFcxng7ph_9YNImLlOr3IbcUkIwt1CRGSh8DO5vC3S6AFCDFtlj9tniKRAu7_HJ5KBUuVDK27fvZbAGoNdMsjEmCbI5rrsmW9n99BRpWIQGjTy4RKHlaiOhWQH6cFCFkXalYbxhv_XFSYyl3QuMpCqhmDWDVZR-0PZ-o_ZzZJT34LsbqSqhN-Bzw4qSCuqyywqlTSdU_Leo73VqeSzsTKj-i17YBDB19ckLalEaEGISxVvWLHyYt9Rv_1lah0JdxI-CHBeB0wWvNPxlv9OL5p8NHxOnda-Riqz_ImuLoV04cEtVpcVdshi6wbBPTce7LJjoT4LgTCzUfmF2xY3K-6fWt22j-3llBZxILJN4XvA3CzDT-5WEkkdRw7Cj37Ol55_W28sbGqNxZDwexPy5xILMaXaw-5kOn8Uag4CgQ0JlDbW0CCs1J8wZmhMiPipHM1s02MpD09Ue7ZfFFPY0QvYrFFa3nCkKpPAlNqK5S6dfvDZaFh3pqwy1c2akOVfHopfCWYwU2s2TuYfU_E5gTA_encf6St-0XBwjhGeHHv-Kj3O-H4tVyLq1FRklA0fysLTGO1Tp1x47qrZ5Bq3sKLWmP1qRO-gM0o4htK9vGDZ2OTtsHb5pOyv08Uf8KW4xJb1v1Hqr_gTtGOwMjvqE\"\n",
    "\n",
    "# Directory and File Handling\n",
    "INPUT_FOLDER = \"support_tickets\"\n",
    "# IMPORTANT: Specify the key in your JSON file that contains the main ticket text.\n",
    "JSON_TICKET_KEY = \"issue_description\" \n",
    "\n",
    "# --- LLM Initialization ---\n",
    "\n",
    "# Initialize the ChatOpenAI client\n",
    "# Note: verify=False disables SSL verification. Not recommended for production.\n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    http_client=httpx.Client(verify=False),\n",
    "    temperature=0.1,  # Lower temperature for more factual, less creative responses\n",
    ")\n",
    "\n",
    "# --- Core Processing Function ---\n",
    "\n",
    "def analyze_and_summarize_ticket(ticket_content):\n",
    "    \"\"\"\n",
    "    Sends ticket content to the LLM for summarization and solution generation.\n",
    "    \"\"\"\n",
    "    # Define a clear, instructional prompt for the model\n",
    "    prompt = f\"\"\"\n",
    "    You are a senior support engineer. Please perform the following tasks for the support ticket below:\n",
    "    1.  Provide a concise one-sentence summary of the user's issue.\n",
    "    2.  Based on the issue, list 3 to 4 potential troubleshooting steps or solutions in a numbered list.\n",
    "\n",
    "    Here is the support ticket:\n",
    "    ---\n",
    "    {ticket_content}\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful senior support engineer.\"),\n",
    "        HumanMessage(content=prompt),\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        return ai_msg.content\n",
    "    except Exception as e:\n",
    "        return f\"Error communicating with the model: {e}\"\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to iterate through JSON files, process them, and save the results.\n",
    "    \"\"\"\n",
    "    # Ensure the input directory exists\n",
    "    if not os.path.isdir(INPUT_FOLDER):\n",
    "        print(f\"Error: The folder '{INPUT_FOLDER}' was not found.\")\n",
    "        print(\"Please create it and place your JSON support tickets inside.\")\n",
    "        return\n",
    "\n",
    "    # Find all JSON files in the directory\n",
    "    json_files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith('.json')]\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in the '{INPUT_FOLDER}' directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(json_files)} support tickets to process...\")\n",
    "\n",
    "    for file_name in json_files:\n",
    "        json_path = os.path.join(INPUT_FOLDER, file_name)\n",
    "        print(f\"\\nProcessing: {file_name}\")\n",
    "\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Extract the ticket text using the specified key\n",
    "            ticket_text = data.get(JSON_TICKET_KEY)\n",
    "\n",
    "            if not ticket_text:\n",
    "                print(f\"  -  Skipping: Could not find key '{JSON_TICKET_KEY}' in the file.\")\n",
    "                continue\n",
    "\n",
    "            # Get the summary and solutions from the model\n",
    "            summary_and_solutions = analyze_and_summarize_ticket(ticket_text)\n",
    "\n",
    "            # Define the output filename\n",
    "            base_name = os.path.splitext(file_name)[0]\n",
    "            output_filename = f\"{base_name}_summary.txt\"\n",
    "            output_path = os.path.join(INPUT_FOLDER, output_filename)\n",
    "\n",
    "            # Save the result to a text file\n",
    "            with open(output_path, 'w') as out_f:\n",
    "                out_f.write(summary_and_solutions)\n",
    "\n",
    "            print(f\"  -  Successfully saved summary to: {output_filename}\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"  -  Skipping: Invalid JSON format in {file_name}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -  An unexpected error occurred: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2eb573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2856969",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
