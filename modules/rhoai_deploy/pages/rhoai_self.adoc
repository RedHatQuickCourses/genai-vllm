= Optional - RHOAI Self-Managed 

For AI platform delivery engineers managing their own Red Hat OpenShift AI instances, this optional section provides critical insights into the necessary prerequisites and component installations for a self-managed environment.

== Core Components for Self-Managed OpenShift AI:

 .  **Red Hat OpenShift AI Operator**: This primary operator orchestrates the deployment of the entire platform.

 .  **Required Operators for Model Serving**:

    *   **OpenShift Service Mesh Operator**: Provides **essential networking capabilities** for secure and reliable communication between model serving microservices.
    *   **OpenShift Serverless Operator**: Enables **efficient resource utilization** by allowing serving pods to scale based on demand, including scaling down to zero. This is vital for cost optimization in dynamic AI workloads.
    *   **Red Hat Authorino Operator**: Provides **protection for deployed models through token-based authentication and authorization**, enabling secure external access. This is a required component for providing secure external access to models.


 .  **NVIDIA GPU Hardware Acceleration**: Access to NVIDIA GPUs is required for high-performance model inference with vLLM.

    *   **Node Feature Discovery (NFD) Operator**: This prerequisite operator **detects hardware features** (like NVIDIA GPUs) across cluster nodes and applies labels. This allows the NVIDIA GPU Operator to identify and manage the correct nodes.
    *   **NVIDIA GPU Operator**: Automates the **complex configuration of GPU-enabled nodes**, managing necessary NVIDIA software components, including drivers and the container runtime, thereby simplifying GPU utilization for AI workloads.
    *   *Installation Sequence*: NFD Operator first, followed by the NVIDIA GPU Operator. After both are installed, a `ClusterPolicy` Custom Resource must be created to initiate GPU worker node configuration.

 .  **Data Science Cluster (DSC)**: After installing the Red Hat OpenShift AI Operator, a `Data Science Cluster` must be created to deploy the platform's services. This `Custom Resource` defines the configuration for the OpenShift AI instance. The deployment typically takes 5-10 minutes, after which the Red Hat OpenShift AI dashboard becomes accessible.


[NOTE]
These operators are available from the OpenShift `OperatorHub`. While the OpenShift AI operator often manages these dependencies, **verification of their installation is prior to the installation of OpenShift AI Operator is advised**.


== Arcade Interactive Experience


++++
<iframe 
  src="https://demo.arcade.software/lie2H2wlw0aDEaR7Q4D5?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%" 
  height="600px" 
  frameborder="0" 
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
++++
