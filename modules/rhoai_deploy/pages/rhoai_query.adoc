= Querying the Deployed Model in a Jupyter Notebook

With our Granite model successfully deployed and running, the final step is to validate it. We will launch our OpenShift AI Workbench, use a Jupyter Notebook to connect to the model's API endpoint, and send it a few test queries to see how it responds.

---

== Part 1: Gather Model Connection Credentials

To connect to our model, we need two key pieces of information: its unique URL (the inference endpoint) and a security token for authentication.

1.  Navigate to your Data Science Project dashboard and select the **Models and model servers** page.
2.  Locate your `granite` or `your-deployment-name` deployment. You should see a green checkmark with a **Running** status.
3.  Click on the deployment name, **granite**, to open its details page.
4.  **Find the Inference Endpoint:** Near the top of the details page, locate the **Inference endpoint** URL. This is the external address for your model. Copy this URL to a temporary text file.
5.  **Find the Authentication Token:** Scroll down to the **Authentication** section. Click the **copy icon** to copy the long security token to your clipboard and paste it into your text file.

We now have the three credentials needed to query our model.

---

== Part 2: Launch the Workbench and Prepare the Notebook

Now, let's launch the Jupyter environment we created earlier.

1.  Navigate to the **Workbench** tab in your project.
2.  Find `Innovatech` or `your-workbench-name` and click the **Launch** icon (the arrow pointing out of a box).

[IMPORTANT]
====
You may be prompted to log in and authorize the workbench to access OpenShift AI resources on your behalf. Use your OpenShift credentials to proceed.
====

Once the JupyterLab interface loads:

.   **Clone the Git Repository:** We need to download the sample notebooks.
    ..  Go to the `lefthand menu bar` and select the Git icon
    ..  From this list, select clone repository.
    ..  In the pop up window paste the following git repository URL.

```bash
git clone https://github.com/RedHatQuickCourses/genai-apps.git
```

.   **Open the Notebook:**
    a.  Using the file browser on the left, navigate into the newly created `genai-apps` folder, and then into the `vllm-rhoai` subdirectory.
    b.  Double-click the `query-a-model.ipynb` file to open the notebook.

---

== Part 3: Configure and Run the Notebook

The notebook is divided into cells. We will execute them one by one to install dependencies, configure our connection, and query the model.

=== Cell 1: Install Libraries

The first cell uses `%pip` to install the `langchain-openai` library, which helps simplify our interaction with the model endpoint.
* Click inside the first cell and press **Shift+Enter** to run it.

=== Cell 2: Configure Connection Variables

This is the most important step. We need to replace the placeholder values in the second cell with the credentials we copied earlier.

.   **VLLM_API_URL**: Replace the placeholder URL with the **Inference endpoint** you copied from the model details page.
.   **VLLM_API_KEY**: Replace the `sha256~token-here` placeholder with the **Authentication Token** you copied.
.   **MODEL_NAME**: The code defaults to `granite`. Replace this with the name of our deployment.

Your configured cell should look similar to this:

```python
# Configure the connection to the vLLM server
VLLM_API_URL = "https://granite-model-vllm-lab.apps.cluster-domain.com/v1"
VLLM_API_KEY = "sha256~AbcDeFgHiJkLmNoPqRsTuVwXyZ..."
MODEL_NAME = "granite"
```

*Execute the cells to send test queries and observe model responses.*

---

== Interactive Demo: Query a Machine Learning Model from a Jupyter Notebook


++++
<iframe 
  src="https://demo.arcade.software/NxmVClp8oaIivhYA5aU6?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%" 
  height="600px" 
  frameborder="0" 
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
++++
