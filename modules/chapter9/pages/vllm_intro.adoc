= Model Selection: Why We Chose Granite

Welcome to the Granite family of models. This page explains what Granite models are, why the `Granite-3.3-2B-instruct` model was selected for this course, and how it fits into the broader ecosystem of enterprise-ready AI.

== What are Granite Models?

**Granite** is a series of large language models (LLMs) created by IBM specifically for enterprise applications. Unlike some other models, the Granite family is built with the needs of businesses at the forefront, emphasizing trust, transparency, and practical application.

What truly sets Granite models apart for enterprise use are two key factors:

* **Open and Assured**: The models are open-sourced under the **Apache 2.0 license**. This allows developers to freely experiment, modify, and deploy the models in their own environments—a critical feature for organizations handling sensitive data that cannot rely on external services.
* **Transparent Training Data**: IBM discloses the data used to train the models, building a foundation of trust and making them more suitable and auditable for enterprise environments.


== The Granite Family: A Model for Every Need

Granite is not a single model but a diverse suite designed for various enterprise tasks. This ecosystem approach means you can select the right tool for the job.

[]
====
*Granite Language Models*:: Base and instruction-tuned models with strong reasoning capabilities, ideal for agentic workflows, Retrieval-Augmented Generation (RAG), summarization, and content generation.

*Granite Vision Models*:: Specialized models for document and image understanding across a range of file types and resolutions.

*Granite Speech Models*:: Compact and efficient models for high-performance transcription and translation tasks.

*Granite for Time Series*:: Lightweight, pre-trained models for time-series forecasting, optimized to run efficiently on various hardware.

*Granite Guardian*:: A safety-focused model designed to mitigate risks and safeguard AI applications by screening for harmful content in both user prompts and LLM responses.

*Granite for Geospatial Data*:: A foundational model created in partnership with NASA, built on large-scale satellite and remote sensing data.

*Granite Embedding Models*:: Models designed to enhance the understanding of user intent, crucial for improving the relevance of information in search and RAG applications.
====



== Our Course Model: A Deep Dive into Granite-3.3-2B-Instruct

The primary model used throughout this course is `ibm-granite/granite-3.3-2b-instruct`. It represents a perfect balance of modern features, manageable size, and robust performance for our learning objectives.

[sidebar]
.Model Snapshot
****
* **Developers**: Granite Team, IBM
* **Release Date**: April 16th, 2025
* **License**: Apache 2.0
* **GitHub**: link:https://github.com/ibm-granite/granite-3.3-language-models[ibm-granite/granite-3.3-language-models]
* **Context Length**: 128,000 tokens
* **Supported Languages**: Excellent in English, with support for German, Spanish, French, Japanese, and more.
****

This is a **2-billion parameter** instruction-following model fine-tuned for enhanced reasoning. It supports structured outputs using `<think>` and `<response>` tags, which provides a clear separation between the model's internal "thought process" and the final answer, a valuable feature for debugging and creating reliable AI agents.

=== Key Capabilities

The model is designed for a wide range of enterprise tasks, including:

* Retrieval Augmented Generation (RAG)
* Question-Answering and Summarization
* Text classification and extraction
* Code generation and function-calling
* Long-context tasks (e.g., summarizing long documents or meetings)


== The Selection Story: A Practical Choice for This Course

Choosing the right model for a course involves balancing performance, accessibility, and relevance to real-world engineering challenges. Here’s why `Granite-3.3-2B-instruct` was the ideal choice:

.A Forward-Looking Foundation
The selection process began with a key technical goal in mind: **quantization**. We needed a full-sized base model that was powerful enough to be useful but small enough to be a practical candidate for a future lab on model optimization. At 2 billion parameters, it hits this sweet spot perfectly.

.The Sweet Spot of Performance and Resources
For AI platform engineers, resource management is critical. A major advantage of this model is its ability to deliver exceptional performance within a manageable resource footprint. Paired with its huge **128K context window**, it allows for sophisticated, long-document analysis while fitting comfortably on a standard **24GB GPU**, a common hardware profile in enterprise labs.

.Exceeding Expectations
Throughout the development of this course, the model consistently provided accurate answers and demonstrated impressive capabilities. While extensive benchmarks against every available model weren't performed, its performance for a model of its size far exceeded all initial expectations.

=== Looking Ahead: The Evolution of Granite

The world of AI moves fast, and the Granite 4 models are now available. Future iterations of this course may incorporate these newer models. This presents an exciting opportunity to create a lab focused on **comparing generational improvements**, allowing students to benchmark the gains in performance, efficiency, and capability from one model generation to the next—a common and valuable task in enterprise AI.