= MinIO S3: Compatible Storage Deployment
:toc:
:toclevels: 2
:sectnums:

== Module 5: Lab 1 - Setting Up the Model Serving Environment

Welcome to the first hands-on lab module. In this section, you will configure the necessary prerequisites within your OpenShift AI project to deploy and serve a large language model.

=== 5.1. Deploying S3-Compatible Storage with MinIO

The OpenShift AI model serving platform pulls model artifacts from an S3-compatible object store. Our first step is to deploy a self-contained object store directly into our data science project.

For this lab, we will use **MinIO**, a high-performance, S3-compatible object store. This guide provides a streamlined method for deploying the community version of MinIO within our `Innovatech` data science project.

[WARNING]
====
This deployment method is intended for lab and prototyping purposes only and should not be used in production environments. Red Hat does not provide commercial support for MinIO.
====

==== MinIO Deployment via OpenShift Console

We will deploy MinIO and its required components by importing a single YAML file that defines all the necessary Kubernetes resources.

.Animated - MinIO Deployment Steps for OpenShift
image::minio_install.gif[width=640]

. From the **Administrator** perspective of the OpenShift Web Console, select the `+Add` action from the top navigation bar. This will open the **Import YAML** page.
. In the YAML editor window, paste the complete deployment code provided in the collapsible block below.
+
[TIP]
It is highly recommended that you change the default `minio_root_user` and `minio_root_password` values in the `Secret` resource before deploying.

. Ensure the target project is set to your data science project, **`Innovatech`**.
. Select the **Create** button to deploy the MinIO resources. The deployment will create a Persistent Volume Claim, a Secret, a Deployment, a Service, and two Routes for API and UI access.

.Click to view and copy the MinIO Deployment YAML
[%collapsible]
====
[source,yaml,linenums]
----
# Defines a 40Gi persistent storage volume for MinIO.
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: minio-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 40Gi
  volumeMode: Filesystem
---
# Defines the secret containing the root credentials for MinIO.
# CHANGE THE DEFAULT VALUES HERE for better security.
kind: Secret
apiVersion: v1
metadata:
  name: minio-secret
stringData:
  minio_root_user: minio # Must be at least 3 characters
  minio_root_password: minio321! # Must be at least 8 characters
---
# The main deployment for the MinIO server pod.
kind: Deployment
apiVersion: apps/v1
metadata:
  name: minio
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: minio-pvc
      containers:
        - name: minio
          image: quay.io/minio/minio:RELEASE.2023-06-19T19-52-50Z
          args:
            - server
            - /data
            - --console-address
            - ':9090'
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: minio_root_user
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: minio_root_password
          ports:
            - containerPort: 9000
              protocol: TCP
            - containerPort: 9090
              protocol: TCP
          volumeMounts:
            - name: data
              mountPath: /data
              subPath: minio
          readinessProbe:
            tcpSocket:
              port: 9000
            initialDelaySeconds: 5
            periodSeconds: 5
          livenessProbe:
            tcpSocket:
              port: 9000
            initialDelaySeconds: 30
            periodSeconds: 5
---
# Exposes the MinIO deployment as a service within the cluster.
kind: Service
apiVersion: v1
metadata:
  name: minio-service
spec:
  ports:
    - name: api
      port: 9000
      targetPort: 9000
    - name: ui
      port: 9090
      targetPort: 9090
  selector:
    app: minio
---
# Creates a public route to the MinIO API service.
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: minio-api
spec:
  to:
    kind: Service
    name: minio-service
  port:
    targetPort: api
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
---
# Creates a public route to the MinIO web console (UI).
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: minio-ui
spec:
  to:
    kind: Service
    name: minio-service
  port:
    targetPort: ui
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
----
====

---

==== MinIO Bucket and Initial File Setup

With the MinIO server running, we now need to configure the storage buckets where our models will reside.

.Animated - Accessing MinIO dashboard and Bucket creation
image::minio_setup.gif[width=640]

. From the **Administrator** perspective, navigate to **Networking -> Routes**. Ensure you have the `Innovatech` project selected.
. You will see two routes: `minio-api` and `minio-ui`. Select the URL for the **`minio-ui`** route to open the MinIO web console in a new browser tab.
+
[NOTE]
If you see an "Application is not available" message, wait a few moments and refresh the page, as the MinIO pod may still be starting.
. Log in to the MinIO Console with the credentials you defined in the `minio-secret` resource (e.g., `minio` / `minio321!`).
. Once logged in, click **Create Bucket**. Create a bucket named **`models`**.
. Next, navigate into the `models` bucket by clicking its name in the **Object Browser**.

===== The "Empty File" Requirement

The OpenShift AI model serving platform validates a deployment by checking that the specified model directory in the object store exists and is not empty. Some runtimes, like the Ollama runtime we may use later, download their own models and don't require pre-loaded artifacts. However, to satisfy the platform's validation check, we must place at least one placeholder file in the target directory.

.Animated - Upload emptyfile.txt to models/ollama
image::minio_file_upload.gif[width=640]

. Inside the `models` bucket, click **Create new path**. Name the new path **`ollama`** and click `Save`.
. You will now be inside the `models/ollama/` path.
. Click the **Upload** button and select **Upload file**.
. Upload a placeholder file named `emptyfile.txt`. You can create a blank text file on your local machine for this purpose.

With our S3-compatible storage deployed and our initial bucket structure configured, we are now ready to configure the other resources in the OpenShift AI platform.