<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Creating the AI Workbench and Preparing Models :: vLLM Optimizing and Serving Models on OpenShift AI</title>
    <link rel="prev" href="rhoai_config.html">
    <link rel="next" href="rhoai_model.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="vLLM Optimizing and Serving Models on OpenShift AI" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../vllm/index.html">vLLM, What is it?</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_intro.html">vLLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/rh_ai.html">Red Hat AI Platforms</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_rhoai.html">Integrating vLLM with OpenShift AI: The Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_deploy.html">vLLM on Red Hat OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_concl.html">Summary: Key Takeaways and Next Steps</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../model_sizing/index.html">GPU Architecture and Model Sizing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_arch.html">NVIDIA GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_cost.html">Estimating GPU VRAM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/vram_calc.html">Cost-Effective Model Selection</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rh_hg_ai/index.html">Red Hat AI Model Repository</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/model_types.html">Generative AI Model Variations in Model Naming</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/val_models.html">Validated Models and Quantization Strategies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/lab_models.html">Pre-Selected Course Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/summary.html">From Curation to Confident Deployment</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_self.html">Optional - RHOAI Self-Managed</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_221.html">Lab Environment Customization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_config.html">Project and Data Connection Setup</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="rhoai_bench.html">Creating the AI Workbench and Preparing Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_model.html">Deploy Granite LLM on RHOAI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_query.html">Querying the Deployed Model in a Jupyter Notebook</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section7.html">Using the AI Model for Summarization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="add_runtime.html">vLLM Serving Runtime</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rhoai_query/index.html">Jupyter Notebooks &amp; LLMs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_query/section1.html">Jupyter Notebooks</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_query/section2.html">Mistral LLM Model Inference</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_query/section3.html">Llama3 LLM Model Inference</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter9/index.html">blank</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter9/section4.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter9/section2.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter9/section3.html">blank</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/further_study.html">Hands on Exploration and Further Study</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Hub: Lab Environment Selection</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/developer_sandbox.html">Red Hat Developer Platform</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM Optimizing and Serving Models on OpenShift AI</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></li>
    <li><a href="index.html">OpenShift AI Configuration</a></li>
    <li><a href="rhoai_bench.html">Creating the AI Workbench and Preparing Models</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Creating the AI Workbench and Preparing Models</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>With our project and data connections configured, it&#8217;s time to create our primary development environment: the <strong>Red Hat OpenShift AI Workbench</strong>. We will then download several open-source Large Language Models (LLMs) and upload them to our MinIO S3 bucket, preparing them for deployment.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_part_1_configure_and_launch_the_workbench"><a class="anchor" href="#_part_1_configure_and_launch_the_workbench"></a>Part 1: Configure and Launch the Workbench</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The workbench provides a fully containerized and interactive data science environment, with JupyterLab as its core component. Here, we will select the right tools, compute resources, and storage connections to build and test our vLLM deployments.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>From your Data Science Project dashboard, click <strong>Create workbench</strong>.</p>
</li>
<li>
<p><strong>Name:</strong> Provide a descriptive name for your workbench, for example, <code>vllm-workbench</code>.</p>
</li>
<li>
<p><strong>Notebook image:</strong> This is the container image that defines your development environment. It includes the operating system, drivers, and pre-installed libraries.</p>
<div class="ulist">
<ul>
<li>
<p>Scroll through the list of available images. You will see options like Standard Python, PyTorch, and TensorFlow.</p>
</li>
<li>
<p>For this lab, it is essential to select an image with NVIDIA GPU support. Choose the <strong>CUDA</strong> notebook image (e.g., <code>CUDA - 12.3.2</code>). This image includes the necessary NVIDIA drivers to communicate with the GPU accelerator.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Container size:</strong> Select the amount of CPU and Memory allocated to your workbench.</p>
<div class="ulist">
<ul>
<li>
<p>The default sizes are Small, Medium, and Large. For this lab, a <strong>Small</strong> or <strong>Medium</strong> instance is sufficient.</p>
</li>
<li>
<p>(Example: Small - 2 CPU, 8 GB RAM; Medium - 4 CPU, 16 GB RAM)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Accelerator:</strong> This is where you attach a physical GPU.</p>
<div class="ulist">
<ul>
<li>
<p>Click the <strong>Select an accelerator</strong> dropdown.</p>
</li>
<li>
<p>Select <strong>NVIDIA GPU</strong>, and ensure the number of accelerators is set to <strong>1</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Data Connections:</strong> Connect the workbench to the S3 storage we configured earlier.</p>
<div class="ulist">
<ul>
<li>
<p>Check the box for the <strong>models-storage</strong> data connection. This will mount our <code>models</code> bucket inside the workbench, making it easy to access.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Cluster storage:</strong> This is the persistent storage for your workbench&#8217;s home directory. Leave the default settings to create a new persistent volume. This ensures your work is saved even if you stop and restart the workbench.</p>
</li>
<li>
<p>Review your selections and click <strong>Create workbench</strong>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The workbench will now begin to provision. This process can take several minutes. While it is starting, we can proceed with the next part of our setup.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_part_2_download_and_upload_ai_models"><a class="anchor" href="#_part_2_download_and_upload_ai_models"></a>Part 2: Download and Upload AI Models</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When we deploy a model server in OpenShift AI, the most common method is to have it download the model files directly from an S3-compatible storage location. We will now download several LLMs from Hugging Face and upload them to our MinIO <code>models</code> bucket.</p>
</div>
<div class="sect2">
<h3 id="_step_a_download_models_from_hugging_face"><a class="anchor" href="#_step_a_download_models_from_hugging_face"></a>Step A: Download Models from Hugging Face</h3>
<div class="paragraph">
<p>On your local computer, create a directory for your models. The easiest way to download a model from Hugging Face is using <code>git</code>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>To save time and disk space, you can perform a "shallow clone" which downloads the latest version without the entire version history. Use the <code>--depth=1</code> flag with your <code>git clone</code> command.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Open a terminal on your local machine and clone the following models. These are relatively small models suitable for a lab environment.</p>
</div>
</div>
<div class="sect2">
<h3 id="_step_b_upload_models_to_minio"><a class="anchor" href="#_step_b_upload_models_to_minio"></a>Step B: Upload Models to MinIO</h3>
<div class="paragraph">
<p>It is a best practice—and often a requirement—that model files reside in a subdirectory within your storage bucket, not in the root. We will create a folder for each model.</p>
</div>
<div class="paragraph">
<p>Log back into the MinIO UI dashboard.</p>
</div>
<div class="paragraph">
<p>Navigate to the models bucket.</p>
</div>
<div class="paragraph">
<p>For each model you downloaded, perform the following actions:
a.  Click Create new path and create a subdirectory named after the model (e.g., Qwen1.5-0.5B-Chat).
b.  Navigate into the newly created path.
c.  Click the Upload button and select Upload folder.
d.  Select the corresponding model folder you cloned onto your local machine to upload all of its contents.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Qwen 1.5 (0.5 Billion parameters)</strong></p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">git clone --depth=1 [https://huggingface.co/RedHatAI/granite-3.1-2b-instruct-FP8-dynamic](https://huggingface.co/RedHatAI/granite-3.1-2b-instruct-FP8-dynamic)</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_interactive_demo_project_deployment_and_data_connection_walkthrough"><a class="anchor" href="#_interactive_demo_project_deployment_and_data_connection_walkthrough"></a>Interactive Demo: Project, Deployment, and Data Connection Walkthrough</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The following interactive demonstration will walk you through the process of:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create a subdirectory named Granite, upload the granite model files.</p>
</li>
<li>
<p>Creating a Workbench in OpenShift AI.</p>
</li>
<li>
<p>Select the appropriate notebook image, size, and data connections.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Follow the on-screen prompts in the demo to complete configuiration process.</p>
</div>
<iframe
  src="https://demo.arcade.software/o95APuRqMKhyFEkEFXhf?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%"
  height="600px"
  frameborder="0"
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="rhoai_config.html">Project and Data Connection Setup</a></span>
  <span class="next"><a href="rhoai_model.html">Deploy Granite LLM on RHOAI</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
