<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Querying the Deployed Model in a Jupyter Notebook :: vLLM Optimizing and Serving Models on OpenShift AI</title>
    <link rel="prev" href="rhoai_model.html">
    <link rel="next" href="batch_summ.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="vLLM Optimizing and Serving Models on OpenShift AI" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../vllm/index.html">vLLM, What is it?</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_intro.html">vLLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/rh_ai.html">Red Hat AI Platforms</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_rhoai.html">Integrating vLLM with OpenShift AI: The Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_deploy.html">vLLM on Red Hat OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_concl.html">Summary: Key Takeaways and Next Steps</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../model_sizing/index.html">GPU Architecture and Model Sizing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_arch.html">NVIDIA GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_cost.html">Estimating GPU VRAM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/vram_calc.html">Cost-Effective Model Selection</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rh_hg_ai/index.html">Red Hat AI Model Repository</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/model_types.html">Generative AI Model Variations in Model Naming</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/val_models.html">Validated Models and Quantization Strategies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/lab_models.html">Pre-Selected Course Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/summary.html">From Curation to Confident Deployment</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_self.html">Optional - RHOAI Self-Managed</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_221.html">Lab Environment Customization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_config.html">Project and Data Connection Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_bench.html">Creating the AI Workbench and Preparing Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="add_runtime.html">vLLM Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai_model.html">Deploy Granite LLM on RHOAI</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="rhoai_query.html">Querying the Deployed Model in a Jupyter Notebook</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="batch_summ.html">Using the AI Model for Batch Summarization</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/further_study.html">Hands on Exploration and Further Study</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Hub: Lab Environment Selection</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/developer_sandbox.html">Red Hat Developer Platform</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM Optimizing and Serving Models on OpenShift AI</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></li>
    <li><a href="index.html">OpenShift AI Configuration</a></li>
    <li><a href="rhoai_query.html">Querying the Deployed Model in a Jupyter Notebook</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Querying the Deployed Model in a Jupyter Notebook</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>With our Granite model successfully deployed and running, the final step is to validate it. We will launch our OpenShift AI Workbench, use a Jupyter Notebook to connect to the model&#8217;s API endpoint, and send it a few test queries to see how it responds.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_part_1_gather_model_connection_credentials"><a class="anchor" href="#_part_1_gather_model_connection_credentials"></a>Part 1: Gather Model Connection Credentials</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To connect to our model, we need two key pieces of information: its unique URL (the inference endpoint) and a security token for authentication.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Navigate to your Data Science Project dashboard and select the <strong>Models and model servers</strong> page.</p>
</li>
<li>
<p>Locate your <code>granite-model</code> deployment. You should see a green checkmark with a <strong>Running</strong> status.</p>
</li>
<li>
<p>Click on the deployment name, <strong>granite-model</strong>, to open its details page.</p>
</li>
<li>
<p><strong>Find the Inference Endpoint:</strong> Near the top of the details page, locate the <strong>Inference endpoint</strong> URL. This is the external address for your model. Copy this URL to a temporary text file.</p>
</li>
<li>
<p><strong>Find the Authentication Token:</strong> Scroll down to the <strong>Authentication</strong> section. Click the <strong>copy icon</strong> to copy the long security token to your clipboard and paste it into your text file.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>We now have the two credentials needed to query our model.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_part_2_launch_the_workbench_and_prepare_the_notebook"><a class="anchor" href="#_part_2_launch_the_workbench_and_prepare_the_notebook"></a>Part 2: Launch the Workbench and Prepare the Notebook</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now, let&#8217;s launch the Jupyter environment we created earlier.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Navigate to the <strong>Workbenches</strong> tab in your project.</p>
</li>
<li>
<p>Find your <code>vllm-workbench</code> and click the <strong>Launch</strong> icon (the arrow pointing out of a box).</p>
</li>
</ol>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You may be prompted to log in and authorize the workbench to access OpenShift AI resources on your behalf. Use your OpenShift credentials to proceed.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Once the JupyterLab interface loads:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Clone the Git Repository:</strong> We need to download the sample notebooks.</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Go to the <code>File</code> menu and select <code>New &#8594; Terminal</code>.</p>
</li>
<li>
<p>In the new terminal window, run the following command to clone the example files:
+
<code><code>bash
git clone [<a href="https://github.com/RedHatQuickCourses/genai-apps.git" class="bare">https://github.com/RedHatQuickCourses/genai-apps.git</a>](<a href="https://github.com/RedHatQuickCourses/genai-apps.git" class="bare">https://github.com/RedHatQuickCourses/genai-apps.git</a>)
</code></code></p>
</li>
</ol>
</div>
</li>
<li>
<p><strong>Open the Notebook:</strong></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Using the file browser on the left, navigate into the newly created <code>genai-apps</code> folder, and then into the <code>vllm-rhoai</code> subdirectory.</p>
</li>
<li>
<p>Double-click the <code>query-a-model.ipynb</code> file to open the notebook.</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_part_3_configure_and_run_the_notebook"><a class="anchor" href="#_part_3_configure_and_run_the_notebook"></a>Part 3: Configure and Run the Notebook</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The notebook is divided into cells. We will execute them one by one to install dependencies, configure our connection, and query the model.</p>
</div>
<div class="sect2">
<h3 id="_cell_1_install_libraries"><a class="anchor" href="#_cell_1_install_libraries"></a>Cell 1: Install Libraries</h3>
<div class="paragraph">
<p>The first cell uses <code>%pip</code> to install the <code>langchain-openai</code> library, which helps simplify our interaction with the model endpoint.
* Click inside the first cell and press <strong>Shift+Enter</strong> to run it.</p>
</div>
</div>
<div class="sect2">
<h3 id="_cell_2_configure_connection_variables"><a class="anchor" href="#_cell_2_configure_connection_variables"></a>Cell 2: Configure Connection Variables</h3>
<div class="paragraph">
<p>This is the most important step. We need to replace the placeholder values in the second cell with the credentials we copied earlier.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>VLLM_API_URL</strong>: Replace the placeholder URL with the <strong>Inference endpoint</strong> you copied from the model details page.</p>
</li>
<li>
<p><strong>VLLM_API_KEY</strong>: Replace the <code>your-token-here</code> placeholder with the <strong>Authentication Token</strong> you copied.</p>
</li>
<li>
<p><strong>MODEL_NAME</strong>: The code defaults to <code>mistralai/Mistral-7B-v0.1</code>. Replace this with the name of our deployment: <code>granite-model</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Your configured cell should look similar to this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Configure the connection to the vLLM server
VLLM_API_URL = "https://granite-model-vllm-lab.apps.cluster-domain.com/v1"
VLLM_API_KEY = "sha256~AbcDeFgHiJkLmNoPqRsTuVwXyZ..."
MODEL_NAME = "granite-model"</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_interactive_demo_query_a_machine_learning_model_from_a_jupyter_notebook"><a class="anchor" href="#_interactive_demo_query_a_machine_learning_model_from_a_jupyter_notebook"></a>Interactive Demo: Query a Machine Learning Model from a Jupyter Notebook</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The following interactive demonstration will walk you through the process of:
1.  lauching a Jupyter Server instance
2.  Cloning a git repository of sample files
3.  Replace URL ENDPOINT, MODEL_NAME, and API TOKEN in the example notebook.
4.  Experimentation with various prompts to see how the model responds.</p>
</div>
<div class="paragraph">
<p>Follow the on-screen prompts in the demo to complete the model deployment.</p>
</div>
<iframe
  src="https://demo.arcade.software/NxmVClp8oaIivhYA5aU6?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%"
  height="600px"
  frameborder="0"
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="rhoai_model.html">Deploy Granite LLM on RHOAI</a></span>
  <span class="next"><a href="batch_summ.html">Using the AI Model for Batch Summarization</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
