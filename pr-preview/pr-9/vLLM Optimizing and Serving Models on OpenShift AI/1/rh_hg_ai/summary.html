<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>From Curation to Confident Deployment :: vLLM Optimizing and Serving Models on OpenShift AI</title>
    <link rel="prev" href="lab_models.html">
    <link rel="next" href="../rhoai_deploy/index.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="vLLM Optimizing and Serving Models on OpenShift AI" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../vllm/index.html">vLLM, What is it?</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_intro.html">vLLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/rh_ai.html">Red Hat AI Platforms</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_rhoai.html">Integrating vLLM with OpenShift AI: The Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_deploy.html">vLLM on Red Hat OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_concl.html">Summary: Key Takeaways and Next Steps</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../model_sizing/index.html">GPU Architecture and Model Sizing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_arch.html">NVIDIA GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_cost.html">Estimating GPU VRAM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/vram_calc.html">Cost-Effective Model Selection</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Red Hat AI Model Repository</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="model_types.html">Generative AI Model Variations in Model Naming</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="val_models.html">Validated Models and Quantization Strategies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="lab_models.html">Pre-Selected Course Models</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="summary.html">From Curation to Confident Deployment</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rhoai_deploy/index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_self.html">Optional - RHOAI Self-Managed</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_221.html">Lab Environment Customization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_config.html">Project and Data Connection Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_bench.html">Creating the AI Workbench and Preparing Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/add_runtime.html">vLLM Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_model.html">Deploy Granite LLM on RHOAI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/rhoai_query.html">Querying the Deployed Model in a Jupyter Notebook</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_deploy/batch_summ.html">Using the AI Model for Batch Summarization</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rhoai_query/index.html">Jupyter Notebooks &amp; LLMs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_query/section1.html">Jupyter Notebooks</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_query/section2.html">Mistral LLM Model Inference</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rhoai_query/section3.html">Llama3 LLM Model Inference</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/further_study.html">Hands on Exploration and Further Study</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Hub: Lab Environment Selection</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/developer_sandbox.html">Red Hat Developer Platform</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM Optimizing and Serving Models on OpenShift AI</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></li>
    <li><a href="index.html">Red Hat AI Model Repository</a></li>
    <li><a href="summary.html">From Curation to Confident Deployment</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">From Curation to Confident Deployment</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>This module has provided a strategic guide to navigating the complex world of open-source model selection. We began by addressing the challenge of finding reliable, enterprise-ready models in a vast ecosystem. We then introduced the Red Hat AI Validated Model Repository as a curated solution that provides confidence, predictability, and cost-efficiency for your AI projects.</p>
</div>
<div class="paragraph">
<p>Through in-depth analysis, we explored how Red Hat validates models, the critical role of quantization, and how to select a model based on its specific architecture, performance, and intended use case.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_key_concepts_revisited"><a class="anchor" href="#_key_concepts_revisited"></a>Key Concepts Revisited</h3>
<div class="paragraph">
<p>Let&#8217;s recap the core ideas from this module:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>The Value of Curation:</strong> A curated repository like Red Hat AI&#8217;s is not just a list of models; it&#8217;s a solution to de-risk projects by providing models that have been pre-vetted for performance, accuracy, and enterprise readiness.</p>
</li>
<li>
<p><strong>Validation Breeds Confidence:</strong> The rigorous validation process, using tools like <code>GuideLLM</code> and <code>LM Eval Harness</code>, provides the transparent data needed to make informed decisions and set realistic expectations for model performance on your target hardware.</p>
</li>
<li>
<p><strong>Quantization is the Key to Cost-Efficiency:</strong> Reducing a model&#8217;s precision is the most effective strategy for fitting powerful models onto cost-effective hardware. We explored the trade-offs between the main strategies: FP8, INT8, and INT4.</p>
</li>
<li>
<p><strong>A Hardware-Aware Strategy is Essential:</strong> The most effective optimization strategies align the model&#8217;s quantization with the GPU&#8217;s native capabilities (e.g., leveraging FP8 support on Hopper, Ada, and Blackwell architectures).</p>
</li>
</ul>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Actionable Takeaways for Platform Engineers</div>
<div class="paragraph">
<p>As you approach your next AI deployment project, apply these practical lessons:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Start with a Validated Repository:</strong> Before diving into the thousands of models on Hugging Face, begin your search with a curated source like the Red Hat AI repository. This will save significant time and reduce the risk of choosing an unsuitable model.</p>
</li>
<li>
<p><strong>The "Model Card" is Your Best Friend:</strong> The detailed analysis provided for each validated model is your primary decision-making tool. Use the benchmark data, especially the accuracy recovery scores, to understand the real-world trade-offs of using a quantized model.</p>
</li>
<li>
<p><strong>Match the Quantization to the Job:</strong></p>
</li>
<li>
<p><strong>Need maximum speed with high accuracy on modern hardware?</strong> Look for <strong>FP8</strong> models.</p>
</li>
<li>
<p><strong>Need a solid balance of performance and savings on a wide range of GPUs?</strong> <strong>INT8</strong> is a reliable choice.</p>
</li>
<li>
<p><strong>Need to fit the largest possible model into a tight memory budget?</strong> <strong>INT4</strong> provides the highest compression.</p>
</li>
<li>
<p><strong>Think in Terms of TCO (Total Cost of Ownership):</strong> Use the performance and efficiency data from the validated models to justify your hardware selections and model choices to stakeholders. Frame your decisions around performance-per-dollar and "Queries Per Dollar" to demonstrate clear business value.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_next_steps_hands_on_deployment_and_evaluation"><a class="anchor" href="#_next_steps_hands_on_deployment_and_evaluation"></a>Next Steps: Hands-On Deployment and Evaluation</h3>
<div class="paragraph">
<p>You now have the theoretical foundation and analytical framework to select models with confidence. In the final module of this course, we will move into the hands-on labs.</p>
</div>
<div class="paragraph">
<p>You will take the three models we analyzed—<code>Mistral-Small</code>, <code>Qwen2.5-VL</code>, and <code>gemma-3</code>—and deploy them using vLLM on OpenShift AI. This practical experience will allow you to see firsthand how their different scales, modalities, and quantization strategies behave in a live environment, solidifying the concepts learned throughout this course.</p>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="lab_models.html">Pre-Selected Course Models</a></span>
  <span class="next"><a href="../rhoai_deploy/index.html">OpenShift AI Configuration</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
