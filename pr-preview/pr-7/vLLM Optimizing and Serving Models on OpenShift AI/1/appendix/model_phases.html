<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Common Generative AI Model Variations :: vLLM Optimizing and Serving Models on OpenShift AI</title>
    <link rel="prev" href="appendix.html">
    <link rel="next" href="further_study.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="vLLM Optimizing and Serving Models on OpenShift AI" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../vllm/index.html">vLLM, What is it?</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_intro.html">vLLM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/rh_ai.html">Red Hat AI Platforms</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_rhoai.html">Integrating vLLM with OpenShift AI: The Serving Runtime</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_deploy.html">vLLM on Red Hat OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../vllm/vllm_concl.html">Summary: Key Takeaways and Next Steps</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../model_sizing/index.html">GPU Architecture and Model Sizing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_arch.html">NVIDIA GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/gpu_cost.html">Estimating GPU VRAM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../model_sizing/vram_calc.html">Cost-Effective Model Selection</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rh_hg_ai/index.html">Red Hat AI Model Repository</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/model_types.html">Generative AI Model Variations in Model Naming</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/val_models.html">Validated Models and Quantization Strategies</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/lab_models.html">Pre-Selected Course Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rh_hg_ai/summary.html">From Curation to Confident Deployment</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter7/index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter7/section1.html">Creating OpenShift AI Resources - 1</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter7/section2.html">MinIO S3 Compatible Storage Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter7/section3.html">OpenShift AI Resources - 2</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter8/index.html">Jupyter Notebooks &amp; LLMs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter8/section1.html">Jupyter Notebooks</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter8/section2.html">Mistral LLM Model Inference</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter8/section3.html">Llama3 LLM Model Inference</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter9/index.html">blank</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter9/section4.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter9/section2.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter9/section3.html">blank</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter9/minios3.html">MinIO S3: Compatible Storage Deployment</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="appendix.html">Appendix</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="model_phases.html">Common Generative AI Model Variations</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="further_study.html">Hands on Exploration and Further Study</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/index-lab-demo.html">Red Hat Demo Hub: Lab Environment Selection</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/developer_sandbox.html">Red Hat Developer Platform</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM Optimizing and Serving Models on OpenShift AI</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM Optimizing and Serving Models on OpenShift AI</a></li>
    <li><a href="appendix.html">Appendix</a></li>
    <li><a href="model_phases.html">Common Generative AI Model Variations</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Common Generative AI Model Variations</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>The landscape of generative AI models is continuously evolving, leading to a diverse set of model variations, each optimized for distinct tasks and behaviors. Understanding these common types and their creation processes leads to effective deployment and application.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_1_base_model"><a class="anchor" href="#_1_base_model"></a>1. Base Model</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>What it is:</strong> A base model, often referred to as a "foundational model," is an LLM trained on an enormous and diverse dataset comprising vast amounts of text and code. It represents the initial, broad learning phase from which more specialized models are subsequently derived.</p>
</li>
<li>
<p><strong>Key Characteristics:</strong></p>
</li>
<li>
<p><strong>Broad Knowledge:</strong> Possesses extensive general knowledge acquired during pre-training.</p>
</li>
<li>
<p><strong>Predictive Nature:</strong> Its core function is to predict the next token (word, subword, or character) in a sequence based on the input it receives.</p>
</li>
<li>
<p><strong>Unstructured Interaction:</strong> Not explicitly trained for conversational interactions, instruction following, or adherence to safety guidelines.</p>
</li>
<li>
<p><strong>Unpredictable Output:</strong> Direct interaction with a raw base model can yield varied and sometimes unpredictable outputs, ranging from completing prompts, answering questions, continuing narratives, or generating less coherent text, all depending on the patterns learned during its extensive training.</p>
</li>
<li>
<p><strong>Analogy:</strong> Consider a base model as a vast, unfiltered digital library. It contains an immense volume of information, but lacks an organized system or a guide (like a librarian) to help users efficiently locate specific information or present it in a structured, helpful manner.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_2_instruct_or_instruction_tuned_model"><a class="anchor" href="#_2_instruct_or_instruction_tuned_model"></a>2. Instruct (or Instruction-Tuned) Model</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>What it is:</strong> An instruct model is a base model that has undergone a critical second phase of training called "instruction fine-tuning" or "alignment." During this phase, it is trained on a meticulously curated dataset consisting of explicit prompts (instructions) paired with high-quality, desired responses. This process frequently incorporates techniques such as Reinforcement Learning with Human Feedback (RLHF) to align the model&#8217;s behavior and responses with human preferences for helpfulness, safety, and conciseness.</p>
</li>
<li>
<p><strong>Key Characteristics:</strong></p>
</li>
<li>
<p><strong>Helpful Assistant:</strong> Designed to act as a responsive and cooperative assistant.</p>
</li>
<li>
<p><strong>Instruction Following:</strong> Exhibits a strong ability to understand and follow specific commands and answer questions directly.</p>
</li>
<li>
<p><strong>Conversational Capability:</strong> Capable of engaging in conversational exchanges and dialogue.</p>
</li>
<li>
<p><strong>Improved Predictability &amp; Safety:</strong> Generally more predictable, reliable, and safer than a base model due to explicit training on desired response patterns and safety guidelines.</p>
</li>
<li>
<p><strong>Common Application:</strong> Most publicly accessible chatbots (e.g., Gemini, ChatGPT, Claude) are examples of instruct-tuned models.</p>
</li>
<li>
<p><strong>Analogy:</strong> This is the same vast library, but now equipped with a highly skilled and helpful librarian. You can articulate your needs or questions, and the librarian will comprehend your request, retrieve relevant information, and present it in a clear, concise, and useful answer, tailored to your instruction.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_3_code_model"><a class="anchor" href="#_3_code_model"></a>3. Code Model</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>What it is:</strong> A code model is a specialized variant of a base or instruct model. It is either pre-trained from scratch on an extensive corpus primarily composed of public source code or has undergone substantial fine-tuning specifically on programming languages and code-related datasets.</p>
</li>
<li>
<p><strong>Key Characteristics:</strong></p>
</li>
<li>
<p><strong>Programming Expertise:</strong> Functions as an expert in various programming-related tasks.</p>
</li>
<li>
<p><strong>Capabilities:</strong> Includes generating code in multiple languages, completing code snippets, debugging existing code, explaining complex code logic, and translating code between different programming languages.</p>
</li>
<li>
<p><strong>Deep Understanding:</strong> While a general instruct model can often generate rudimentary code, a dedicated code model possesses a far deeper understanding of programming syntax, standard libraries, APIs, and common architectural patterns, leading to significantly higher-quality and more accurate code outputs.</p>
</li>
<li>
<p><strong>Analogy:</strong> Envision this as a highly specialized technical library exclusively dedicated to computer science and programming. This library is staffed by a librarian who is not only knowledgeable about books but is also an experienced software developer, capable of directly assisting with coding challenges.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_4_chat_model"><a class="anchor" href="#_4_chat_model"></a>4. Chat Model</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>What it is:</strong> A chat model is a specific type of instruct-tuned model rigorously optimized for multi-turn conversations and sustained dialogue. While many instruct models possess conversational abilities, "chat models" are specifically fine-tuned to maintain contextual awareness of prior turns in a conversation, enabling them to generate more coherent, relevant, and engaging responses over extended interactions.</p>
</li>
<li>
<p><strong>Key Characteristics:</strong></p>
</li>
<li>
<p><strong>Coherent Dialogue:</strong> Excels at maintaining a natural and fluid back-and-forth conversation.</p>
</li>
<li>
<p><strong>Context Retention:</strong> Demonstrates superior capability in handling follow-up questions, requests for clarification, and references to earlier parts of the dialogue history.</p>
</li>
<li>
<p><strong>Enhanced User Experience:</strong> Leads to a more seamless and intuitive conversational experience for the end-user.</p>
</li>
<li>
<p><strong>Analogy:</strong> This is a librarian who not only answers your initial inquiry but also actively remembers the entire discussion, engaging in a detailed and continuous dialogue while seamlessly referencing previous points in your conversation.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_5_summarization_model_task_specific_fine_tune"><a class="anchor" href="#_5_summarization_model_task_specific_fine_tune"></a>5. Summarization Model (Task-Specific Fine-Tune)</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>What it is:</strong> "TL;DR" (Too Long; Didnâ€™t Read) describes a common task, and models are frequently fine-tuned specifically for this purpose. A summarization model is trained on a dataset comprising pairs of lengthy documents and their corresponding concise summaries.</p>
</li>
<li>
<p><strong>Key Characteristics:</strong></p>
</li>
<li>
<p><strong>Condensation Expertise:</strong> Highly skilled at processing substantial blocks of text (e.g., articles, research papers, email threads) and condensing them into brief, accurate summaries that encapsulate the main points.</p>
</li>
<li>
<p><strong>Abstractive vs. Extractive:</strong> Specialized summarization models are often more adept at producing high-quality <strong>abstractive</strong> summaries (generating new sentences to capture meaning) rather than merely <strong>extractive</strong> summaries (pulling key sentences directly from the source text). While a general-purpose instruct model can summarize, a dedicated summarization model typically offers superior results for this specific task.</p>
</li>
<li>
<p><strong>Analogy:</strong> This is a librarian who possesses an exceptional ability to read a voluminous book and then provide a perfect, succinct one-paragraph synopsis that captures its essence.</p>
</li>
</ul>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="appendix.html">Appendix</a></span>
  <span class="next"><a href="further_study.html">Hands on Exploration and Further Study</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
